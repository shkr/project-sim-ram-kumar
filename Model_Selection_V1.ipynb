{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix, classification_report,precision_recall_curve\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>peripher neuropathi wikipedia free encyclopedi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>colorado tick fever wikipedia free encyclopedi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rosselli gulienetti syndrom wikipedia free enc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>johanson blizzard syndrom wikipedia free encyc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>digeorg syndrom wikipedia free encyclopedia di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  y\n",
       "0  peripher neuropathi wikipedia free encyclopedi...  1\n",
       "1  colorado tick fever wikipedia free encyclopedi...  1\n",
       "2  rosselli gulienetti syndrom wikipedia free enc...  1\n",
       "3  johanson blizzard syndrom wikipedia free encyc...  1\n",
       "4  digeorg syndrom wikipedia free encyclopedia di...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('./input/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"article\"] = df[\"article\"].astype(str)\n",
    "X = df['article'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y']\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_count\"] = df[\"article\"].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>13695.000000</td>\n",
       "      <td>13695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.269806</td>\n",
       "      <td>358.812267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.443875</td>\n",
       "      <td>647.346822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  y    word_count\n",
       "count  13695.000000  13695.000000\n",
       "mean       0.269806    358.812267\n",
       "std        0.443875    647.346822\n",
       "min        0.000000      1.000000\n",
       "25%        0.000000     41.000000\n",
       "50%        0.000000    126.000000\n",
       "75%        1.000000    376.000000\n",
       "max        1.000000  18163.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Tokens 130371\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Number of Unique Tokens',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Tensor: (13695, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Data Tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,y, test_size=0.10, random_state=42, stratify=np.argmax(y, axis=1))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.05, random_state=42, stratify=np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11708, 1000) (11708, 2)\n",
      "(1370, 1000) (1370, 2)\n",
      "(617, 1000) (1370, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_val.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8549.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        3159.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_trainable_embedding_model():\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,trainable=True)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "    l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "    l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "    l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "    l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "    l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "    l_flat = Flatten()(l_pool3)\n",
    "    l_dense = Dense(128, activation='relu')(l_flat)\n",
    "    preds = Dense(2, activation='softmax')(l_dense)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    print(\"Simplified convolutional neural network\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Simplified convolutional neural network\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         13037200  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 996, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 195, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 13,282,194\n",
      "Trainable params: 13,282,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = cnn_trainable_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp=ModelCheckpoint('model_cnn_v1.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11708 samples, validate on 617 samples\n",
      "Epoch 1/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9849\n",
      "Epoch 00001: val_acc improved from -inf to 0.99190, saving model to model_cnn_v1.hdf5\n",
      "11708/11708 [==============================] - 157s 13ms/sample - loss: 0.0534 - acc: 0.9850 - val_loss: 0.0339 - val_acc: 0.9919\n",
      "Epoch 2/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9942\n",
      "Epoch 00002: val_acc did not improve from 0.99190\n",
      "11708/11708 [==============================] - 154s 13ms/sample - loss: 0.0246 - acc: 0.9942 - val_loss: 0.0495 - val_acc: 0.9870\n",
      "Epoch 3/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9958\n",
      "Epoch 00003: val_acc did not improve from 0.99190\n",
      "11708/11708 [==============================] - 148s 13ms/sample - loss: 0.0183 - acc: 0.9957 - val_loss: 0.0663 - val_acc: 0.9806\n",
      "Epoch 4/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9976\n",
      "Epoch 00004: val_acc did not improve from 0.99190\n",
      "11708/11708 [==============================] - 148s 13ms/sample - loss: 0.0143 - acc: 0.9976 - val_loss: 0.0973 - val_acc: 0.9870\n",
      "Epoch 5/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9980\n",
      "Epoch 00005: val_acc did not improve from 0.99190\n",
      "11708/11708 [==============================] - 133s 11ms/sample - loss: 0.0169 - acc: 0.9980 - val_loss: 0.1015 - val_acc: 0.9887\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=5, batch_size=32,callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(conf_matrix)\n",
    "    print(f1_score(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[989  11]\n",
      " [  8 362]]\n",
      "0.9744279946164199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1000\n",
      "           1       0.97      0.98      0.97       370\n",
      "\n",
      "    accuracy                           0.99      1370\n",
      "   macro avg       0.98      0.98      0.98      1370\n",
      "weighted avg       0.99      0.99      0.99      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[991   9]\n",
      " [  4 366]]\n",
      "0.9825503355704698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1000\n",
      "           1       0.98      0.99      0.98       370\n",
      "\n",
      "    accuracy                           0.99      1370\n",
      "   macro avg       0.99      0.99      0.99      1370\n",
      "weighted avg       0.99      0.99      0.99      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since the best model is yielded in earier epochs lets load the best model and test the same\n",
    "model.load_weights('./model_cnn_v1.hdf5')\n",
    "y_pred = predict(model, X_test)\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_trainable_embedding_model_with_reg():\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,trainable=True)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    l_cov1= Conv1D(128, 5, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(embedded_sequences)\n",
    "    l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "    l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "    l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "    l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "    l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "    l_flat = Flatten()(l_pool3)\n",
    "    l_dense = Dense(128, activation='relu')(l_flat)\n",
    "    preds = Dense(2, activation='softmax')(l_dense)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    print(\"Simplified convolutional neural network\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified convolutional neural network\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 100)         13037200  \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 996, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 195, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 13,282,194\n",
      "Trainable params: 13,282,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_v2  = cnn_trainable_embedding_model_with_reg()\n",
    "cp_v2=ModelCheckpoint('model_cnn_v2.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11708 samples, validate on 617 samples\n",
      "Epoch 1/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9656\n",
      "Epoch 00001: val_acc improved from -inf to 0.98379, saving model to model_cnn_v2.hdf5\n",
      "11708/11708 [==============================] - 155s 13ms/sample - loss: 0.1948 - acc: 0.9657 - val_loss: 0.0716 - val_acc: 0.9838\n",
      "Epoch 2/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9885\n",
      "Epoch 00002: val_acc improved from 0.98379 to 0.98541, saving model to model_cnn_v2.hdf5\n",
      "11708/11708 [==============================] - 147s 13ms/sample - loss: 0.0484 - acc: 0.9886 - val_loss: 0.0609 - val_acc: 0.9854\n",
      "Epoch 3/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9910\n",
      "Epoch 00003: val_acc did not improve from 0.98541\n",
      "11708/11708 [==============================] - 147s 13ms/sample - loss: 0.0458 - acc: 0.9910 - val_loss: 0.0681 - val_acc: 0.9838\n",
      "Epoch 4/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9935\n",
      "Epoch 00004: val_acc improved from 0.98541 to 0.99028, saving model to model_cnn_v2.hdf5\n",
      "11708/11708 [==============================] - 137s 12ms/sample - loss: 0.0297 - acc: 0.9934 - val_loss: 0.0595 - val_acc: 0.9903\n",
      "Epoch 5/5\n",
      "11680/11708 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9942\n",
      "Epoch 00005: val_acc did not improve from 0.99028\n",
      "11708/11708 [==============================] - 149s 13ms/sample - loss: 0.0274 - acc: 0.9942 - val_loss: 0.0891 - val_acc: 0.9854\n"
     ]
    }
   ],
   "source": [
    "history_v2 = model_v2.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  epochs=5, batch_size=32,\n",
    "                  class_weight=class_weights,\n",
    "                  callbacks=[cp_v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[994   6]\n",
      " [  9 361]]\n",
      "0.9796472184531886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1000\n",
      "           1       0.98      0.98      0.98       370\n",
      "\n",
      "    accuracy                           0.99      1370\n",
      "   macro avg       0.99      0.98      0.99      1370\n",
      "weighted avg       0.99      0.99      0.99      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(model_v2, X_test)\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[994   6]\n",
      " [  9 361]]\n",
      "0.9796472184531886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1000\n",
      "           1       0.98      0.98      0.98       370\n",
      "\n",
      "    accuracy                           0.99      1370\n",
      "   macro avg       0.99      0.98      0.99      1370\n",
      "weighted avg       0.99      0.99      0.99      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let load the best model and test the same\n",
    "model_v2.load_weights('./model_cnn_v2.hdf5')\n",
    "y_pred = predict(model_v2, X_test)\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
